<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pyspectools.models package &#8212; PySpecTools 4.4.0 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pyspectools.qchem package" href="pyspectools.qchem.html" />
    <link rel="prev" title="pyspectools.mmw package" href="pyspectools.mmw.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          PySpecTools</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">PySpecTools FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="pyspectools.spectra.html"><cite>Spectra</cite> Module</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="api.html">API Reference</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">pyspectools.models package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-pyspectools.models.classes">pyspectools.models.classes module</a></li>
<li><a class="reference internal" href="#module-pyspectools.models.torch_models">pyspectools.models.torch_models module</a></li>
<li><a class="reference internal" href="#module-pyspectools.models">Module contents</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="pyspectools.mmw.html" title="Previous Chapter: pyspectools.mmw package"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; pyspectools.m...</span>
    </a>
  </li>
  <li>
    <a href="pyspectools.qchem.html" title="Next Chapter: pyspectools.qchem package"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">pyspectools.q... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/pyspectools.models.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="pyspectools-models-package">
<h1>pyspectools.models package<a class="headerlink" href="#pyspectools-models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pyspectools.models.classes">
<span id="pyspectools-models-classes-module"></span><h2>pyspectools.models.classes module<a class="headerlink" href="#module-pyspectools.models.classes" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="pyspectools.models.classes.MoleculeDetective">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.classes.</code><code class="sig-name descname">MoleculeDetective</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weights_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">'cpu'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#MoleculeDetective"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.MoleculeDetective" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt id="pyspectools.models.classes.MoleculeDetective.run_inference">
<code class="sig-name descname">run_inference</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">specconst_obj</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#pyspectools.models.classes.SpecConstants" title="pyspectools.models.classes.SpecConstants">pyspectools.models.classes.SpecConstants</a></span></em>, <em class="sig-param"><span class="n">composition</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">N</span><span class="o">=</span><span class="default_value">1000</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#MoleculeDetective.run_inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.MoleculeDetective.run_inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Use a pre-trained PyTorch model to perform inference, conditional on the
experimental constants and the expected composition. This framework can
be used to account for various forms of uncertainties, and the default
behavior is to provide the minimum amount of information. For example,
the <cite>composition</cite> argument can be provided as an <cite>int</cite> type representing:</p>
<p>[0: hydrocarbon, 1: oxygen-bearing, 2: nitrogen-bearing, 3: ON-bearing]</p>
<p>By default, <cite>composition</cite> is None; the case where we don’t know what
the composition is, in which case we will randomly try all four compositions.</p>
<p>This implementation is set up to take advantage of performance in <cite>torch</cite>. Rather
than repeatedly call a function a la MCMC sampling, we simply pass an entire tensor
of all the samples so that <cite>torch</cite> can run without Python interaction. You can
think of each row as a “minibatch”.</p>
<p>The constants are converted to GHz, and therefore expected as MHz.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>specconst_obj</strong> (<em>[</em><em>type</em><em>]</em>) – <cite>SpecConstants</cite> object, which will generate random samples
based on the experimental uncertainties.</p></li>
<li><p><strong>composition</strong> (<em>int</em><em> or </em><em>None</em><em> (</em><em>default</em><em>)</em><em>, </em><em>optional</em>) – The expected composition of the molecule. When <cite>composition</cite> is
an integer, inference is performed conditional on the specific
composition; the definitions are provided in the docstring.
If <cite>None</cite> (default), we have no prior knowledge of the composition,
and will randomly test all four.</p></li>
<li><p><strong>N</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of samples to run, by default 1000</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>NumPy arrays corresponding to the predicted eigenspectrum,
molecular formula, and functional groups present. <cite>functional</cite>
is output as log sigmoid by the model, and this function
returns the exponential to get back sigmoid likelihoods.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>eigenspectrum, formula, functional</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pyspectools.models.classes.MoleculeResult">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.classes.</code><code class="sig-name descname">MoleculeResult</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">eigenspectrum</span></em>, <em class="sig-param"><span class="n">formulas</span></em>, <em class="sig-param"><span class="n">functional_groups</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#MoleculeResult"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.MoleculeResult" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt id="pyspectools.models.classes.MoleculeResult.analyze">
<code class="sig-name descname">analyze</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">q</span><span class="o">=</span><span class="default_value">0.025, 0.5, 0.975</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#MoleculeResult.analyze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.MoleculeResult.analyze" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience function to compute some summary statistics, and make interactive
plotly figures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>q</strong> (<em>tuple</em><em>, </em><em>optional</em>) – [description], by default (0.025, 0.5, 0.975)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>fig</em> – Plotly Figure object</p></li>
<li><p><em>results</em> – dict containing summary statistics of the formula/functional
predictions.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pyspectools.models.classes.MoleculeResult.func_encoding">
<code class="sig-name descname">func_encoding</code><em class="property"> = ['Aliphatic', 'Allene', 'Vinyl', 'Alkyne', 'Carbonyl (General)', 'Carbonyl (α-nitrogen)', 'Carbonyl (α-carbon)', 'Aldehyde', 'Amide', 'Ketone', 'Ether', 'Amine', 'Amino acid', 'Nitrate', 'Nitrile', 'Isonitrile', 'Nitro', 'Alcohol', 'Alcohol (Carboxylic acid)', 'Enol', 'Phenol', 'Peroxide', 'Aromatic sp2 carbon']</em><a class="headerlink" href="#pyspectools.models.classes.MoleculeResult.func_encoding" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pyspectools.models.classes.SpecConstants">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.classes.</code><code class="sig-name descname">SpecConstants</code><span class="sig-paren">(</span><em class="sig-param">A: str</em>, <em class="sig-param">B: str</em>, <em class="sig-param">C: str</em>, <em class="sig-param">u_a=0.0+/-3.0</em>, <em class="sig-param">u_b=0.0+/-3.0</em>, <em class="sig-param">u_c=0.0+/-3.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#SpecConstants"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.SpecConstants" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class representing experimental parameters to be fed into the
<cite>MoleculeDetective</cite> model. The user provides a set of constants
as input, and the main purpose of this class is to help manage
experimental uncertainties.</p>
<dl class="py method">
<dt id="pyspectools.models.classes.SpecConstants.generate_samples">
<code class="sig-name descname">generate_samples</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#SpecConstants.generate_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.SpecConstants.generate_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to generate samples of spectroscopic parameters, based on
“diagonal” Gaussians. The nominal value and standard deviations of
each parameter are used parameterize a Gaussian, and <cite>N</cite> random
samples are drawn. In the case of the dipole moments, we take the
absolute value of the samples, and delta and kappa are recalculated
based on the drawn A, B, C.</p>
<p>TODO - Make this code look cleaner; there must be a smarter way to sample</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>N</strong> (<em>int</em>) – Number of samples to generate.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>2D np.ndarray, where columns correspond to parameter, and rows
are samples</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspectools.models.classes.SpecConstants.load">
<em class="property">classmethod </em><code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#SpecConstants.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.SpecConstants.load" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="pyspectools.models.classes.SpecConstants.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/classes.html#SpecConstants.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.classes.SpecConstants.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the molecule to disk using Pickle in <cite>joblib</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em>, </em><em>optional</em>) – Name to save the molecule to, not including the
extension “.pkl”, by default None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyspectools.models.torch_models">
<span id="pyspectools-models-torch-models-module"></span><h2>pyspectools.models.torch_models module<a class="headerlink" href="#module-pyspectools.models.torch_models" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="pyspectools.models.torch_models.GenericModel">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.torch_models.</code><code class="sig-name descname">GenericModel</code><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#GenericModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.GenericModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt id="pyspectools.models.torch_models.GenericModel.compute_loss">
<em class="property">abstract </em><code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#GenericModel.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.GenericModel.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="pyspectools.models.torch_models.GenericModel.get_num_parameters">
<code class="sig-name descname">get_num_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/pyspectools/models/torch_models.html#GenericModel.get_num_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.GenericModel.get_num_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the number of parameters contained within the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Number of trainable parameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspectools.models.torch_models.GenericModel.init_layers">
<code class="sig-name descname">init_layers</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weight_func</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">bias_func</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#GenericModel.init_layers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.GenericModel.init_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that will initialize all the weights and biases of
the model layers. This function uses the <cite>apply</cite> method of
<cite>Module</cite>, and so will only work on layers that are contained
as children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight_func</strong> (<cite>nn.init</cite> function, optional) – Function to use to initialize weights, by default None
which will default to <cite>nn.init.xavier_normal</cite></p></li>
<li><p><strong>bias_func</strong> (<cite>nn.init</cite> function, optional) – Function to use to initialize biases, by default None
which will default to <cite>nn.init.xavier_uniform</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspectools.models.torch_models.GenericModel.load_weights">
<em class="property">classmethod </em><code class="sig-name descname">load_weights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weights_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#GenericModel.load_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.GenericModel.load_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience method for loading in the weights of a model.
Basically initializes the model, and wraps a <cite>torch.load</cite>
with automatic cuda/cpu detection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights_path</strong> (<em>str</em>) – String path to the trained weights of a model; typically
with extension .pt</p></li>
<li><p><strong>device</strong> (<em>str</em>) – String reference to the target device, either “cpu”, “cuda”,
or a specific CUDA device (e.g. “cuda:0”). If None (default)
the model will be loaded onto a GPU if available, otherwise
a CPU.</p></li>
<li><p><strong>are passed into the creation of the model</strong><strong>, </strong><strong>allowing you</strong> (<em>kwargs</em>) – </p></li>
<li><p><strong>set different parameters.</strong> (<em>to</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Instance of the PyTorch model with loaded weights</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pyspectools.models.torch_models.VarMolDetect">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.torch_models.</code><code class="sig-name descname">VarMolDetect</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">eigen_length</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">latent_dim</span><span class="o">=</span><span class="default_value">14</span></em>, <em class="sig-param"><span class="n">nclasses</span><span class="o">=</span><span class="default_value">23</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">tracker</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VarMolDetect"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VarMolDetect" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyspectools.models.torch_models.GenericModel" title="pyspectools.models.torch_models.GenericModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspectools.models.torch_models.GenericModel</span></code></a></p>
<p>Umbrella model that encapsulates the full set of variational
models. The premise is to more or less try to do end-to-end
learning, and should meet the user half-way in terms of
usability. The <cite>forward</cite> method takes the spectroscopic constants
and the molecular composition as separate inputs, and performs
the concatenation prior to any calculation. The composition
is reused by the <cite>VariationalDecoder</cite> model.</p>
<dl class="py method">
<dt id="pyspectools.models.torch_models.VarMolDetect.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">constants</span></em>, <em class="sig-param"><span class="n">composition</span></em>, <em class="sig-param"><span class="n">eigenspectrum</span></em>, <em class="sig-param"><span class="n">formula</span></em>, <em class="sig-param"><span class="n">functionals</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VarMolDetect.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VarMolDetect.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="pyspectools.models.torch_models.VarMolDetect.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">constants</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">composition</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VarMolDetect.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VarMolDetect.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pyspectools.models.torch_models.VariationalDecoder">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.torch_models.</code><code class="sig-name descname">VariationalDecoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">latent_dim</span><span class="o">=</span><span class="default_value">14</span></em>, <em class="sig-param"><span class="n">eigen_length</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">nclasses</span><span class="o">=</span><span class="default_value">23</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">loss_func</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">param_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tracker</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VariationalDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VariationalDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyspectools.models.torch_models.GenericModel" title="pyspectools.models.torch_models.GenericModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspectools.models.torch_models.GenericModel</span></code></a></p>
<p>This model uses the intermediate eigenspectrum to calculate a
latent embedding that is then used to predict the molecular
formula and functional groups. You can think of the first action
as “re-encoding”, but the driving principle is that an eigenspectrum
could map onto various structures, even when conditional on the
composition.</p>
<dl class="py method">
<dt id="pyspectools.models.torch_models.VariationalDecoder.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">formula</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">groups</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VariationalDecoder.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VariationalDecoder.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the joint loss of this model. This corresponds to the sum
of three components: a KL-divergence loss for the variational layer,
a formula prediction accuracy as the MSE loss, and the BCE loss for the
multilabel classification for the functional group prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – [description]</p></li>
<li><p><strong>formula</strong> (<em>torch.Tensor</em>) – Length of the formula encoding, typically 4 [H,C,O,N]</p></li>
<li><p><strong>groups</strong> (<em>torch.Tensor</em>) – Length of the functional groups encoding.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspectools.models.torch_models.VariationalDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VariationalDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VariationalDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a forward pass of the VariationalDecoder model.
This takes the concatenated input of the eigenspectrum and
the one-hot composition, produces a latent embedding that
is then used to predict the formula and functional group
classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – [description]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>formula_output</em> – Nx4 tensor corresponding to the number of atoms
in the [H,C,O,N] positions.</p></li>
<li><p><em>functional_output</em> – Nx23 tensor corresponding to multilabel classification,
provided as log sigmoid.</p></li>
<li><p><em>mu, logvar</em> – Latent variables of the variational layer</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pyspectools.models.torch_models.VariationalSpecDecoder">
<em class="property">class </em><code class="sig-prename descclassname">pyspectools.models.torch_models.</code><code class="sig-name descname">VariationalSpecDecoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">latent_dim</span><span class="o">=</span><span class="default_value">14</span></em>, <em class="sig-param"><span class="n">output_dim</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">loss_func</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">opt_settings</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">param_transform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tracker</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VariationalSpecDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VariationalSpecDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyspectools.models.torch_models.GenericModel" title="pyspectools.models.torch_models.GenericModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspectools.models.torch_models.GenericModel</span></code></a></p>
<p>Uses variational inference to capture the uncertainty
with respect to Coulomb matrix eigenvalues. Instead of
using dropout, this model represents uncertainty via a
probabilistic latent layer.</p>
<dl class="py method">
<dt id="pyspectools.models.torch_models.VariationalSpecDecoder.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">Y</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VariationalSpecDecoder.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VariationalSpecDecoder.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the loss of this model as the combined prediction error
and KL-divergence from the approximate posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Combined tensor of the spectroscopic constants and the one-hot
encoded composition.</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – Target eigenspectrum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Joint loss of MSE and KL divergence</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspectools.models.torch_models.VariationalSpecDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyspectools/models/torch_models.html#VariationalSpecDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspectools.models.torch_models.VariationalSpecDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Inputs for this model is a single Tensor, where each row
is 12 elements long (8 constants, one-hot encoding for
composition). The idea behind this is to predict the
eigenspectrum conditional on the molecular composition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor containing spectroscopic constants, and
one-hot encoding of the composition.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The predicted eigenspectrum, and the latent parameters
mu and logvar</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>output, mu, logvar</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyspectools.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pyspectools.models" title="Permalink to this headline">¶</a></h2>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2017—2020, Kelvin Lee.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>